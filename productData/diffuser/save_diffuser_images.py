import os
import json
import requests
import time

# JSON íŒŒì¼ ê²½ë¡œ
JSON_PATH = "C:\\Users\\EZEN\\Documents\\data\\productData\\diffuser\\diffuser.json"

# ì´ë¯¸ì§€ ì €ì¥ ê¸°ë³¸ ê²½ë¡œ
SAVE_DIR = "C:\\Users\\EZEN\\Documents\\data\\productData\\diffuser\\images"

# ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
MAX_RETRIES = 5

# ìš”ì²­ í—¤ë” ì„¤ì • (ë¸Œë¼ìš°ì €ì²˜ëŸ¼ ë³´ì´ë„ë¡)
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Referer": "https://www.diptyqueparis.com/"
}


def download_image(url, save_path):
    """ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³  ì €ì¥í•˜ëŠ” í•¨ìˆ˜"""
    retries = 0
    while retries < MAX_RETRIES:
        try:
            response = requests.get(url, headers=HEADERS, timeout=10)
            if response.status_code == 200:
                with open(save_path, "wb") as file:
                    file.write(response.content)
                print(f"âœ… ë‹¤ìš´ë¡œë“œ ì„±ê³µ: {save_path}")
                return True
            else:
                print(f"âš ï¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ [{response.status_code}] {url}")
        except requests.exceptions.RequestException as e:
            print(f"âš ï¸ ìš”ì²­ ì˜¤ë¥˜: {e}")

        retries += 1
        print(f"ğŸ”„ ì¬ì‹œë„ ({retries}/{MAX_RETRIES})...")
        time.sleep(1)  # ì¬ì‹œë„ ì „ì— 2ì´ˆ ëŒ€ê¸°

    print(f"âŒ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼: {url}")
    return False


def process_images():
    """JSON ë°ì´í„°ë¥¼ ì½ê³ , ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ í›„ ì €ì¥í•˜ëŠ” í•¨ìˆ˜"""
    if not os.path.exists(JSON_PATH):
        print(f"âŒ JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {JSON_PATH}")
        return

    with open(JSON_PATH, "r", encoding="utf-8") as file:
        data = json.load(file)

    failed_downloads = []

    for item in data:
        product_type = item["type"].replace(" ", "_")
        product_name = item["name"].replace(" ", "_")

        base_path = os.path.join(SAVE_DIR, "diffuser", product_type, product_name)
        thumbnail_path = os.path.join(base_path, "thumbnail")
        detail_path = os.path.join(base_path, "detail")

        os.makedirs(thumbnail_path, exist_ok=True)
        os.makedirs(detail_path, exist_ok=True)

        for option in item.get("options", []):
            images = option.get("images", {})

            # ì¸ë„¤ì¼ ì´ë¯¸ì§€ ì €ì¥
            for thumb_type, url in images.get("thumbnail", {}).items():
                file_name = f"{thumb_type}.jpg"
                save_path = os.path.join(thumbnail_path, file_name)
                if not os.path.exists(save_path):  # ì´ë¯¸ ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ì€ ê±´ë„ˆë›°ê¸°
                    if not download_image(url, save_path):
                        failed_downloads.append((url, save_path))

            # ë””í…Œì¼ ì´ë¯¸ì§€ ì €ì¥
            for idx, url in enumerate(images.get("detail", [])):
                file_name = f"detail_{idx + 1}.jpg"
                save_path = os.path.join(detail_path, file_name)
                if not os.path.exists(save_path):  # ì´ë¯¸ ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ì€ ê±´ë„ˆë›°ê¸°
                    if not download_image(url, save_path):
                        failed_downloads.append((url, save_path))

    # ì‹¤íŒ¨í•œ ì´ë¯¸ì§€ ë‹¤ì‹œ ì‹œë„
    retry_failed_downloads(failed_downloads)


def retry_failed_downloads(failed_list):
    """ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨í•œ íŒŒì¼ë“¤ì„ ë‹¤ì‹œ ì‹œë„í•˜ëŠ” í•¨ìˆ˜"""
    remaining_failures = []

    for url, save_path in failed_list:
        if not download_image(url, save_path):
            remaining_failures.append((url, save_path))

    if remaining_failures:
        print("\nâŒ ì—¬ì „íˆ ì‹¤íŒ¨í•œ íŒŒì¼ë“¤:")
        for url, _ in remaining_failures:
            print(url)


if __name__ == "__main__":
    process_images()
